PORT=5000

# API Keys Configuration
# Works with either OPENAI_API_KEY, OPENROUTER_API_KEY, or both!
# 
# If both are set:
#   - OpenAI is tried first (for both embeddings and chat)
#   - OpenRouter automatically used as fallback if OpenAI fails
# 
# If only one is set:
#   - That API will be used for all operations
# 
# To force OpenRouter for embeddings (even if OpenAI works):
#   Set USE_OPENROUTER_FOR_EMBEDDINGS=true

OPENAI_API_KEY=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
OPENROUTER_API_KEY=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

# Force OpenRouter for embeddings (set to 'true' if OpenAI has quota issues)
USE_OPENROUTER_FOR_EMBEDDINGS=false

# Model configuration
# Using OpenAI models directly
CHAT_MODEL=gpt-3.5-turbo
EMBEDDING_MODEL=text-embedding-3-small

# Token limits
# This is OUTPUT tokens only. Input tokens (your prompt) are separate.
# Set to maximum for longest possible responses - monitor your usage!
# For OpenAI: gpt-3.5-turbo supports up to 4096 tokens
# For OpenRouter: Be careful with free tier - adjust if you hit credit limits
MAX_TOKENS=4096

# Input token limits - increased for better context understanding
# Maximum number of document context chunks to include per search
MAX_CONTEXT_CHUNKS=5
# Maximum total context chunks across all documents
MAX_TOTAL_CONTEXT_CHUNKS=8
# Maximum conversation history messages to include (more context for better responses)
MAX_HISTORY_MESSAGES=5
# Maximum characters per context chunk (longer chunks = more context)
MAX_CHUNK_LENGTH=600

# Note: If using OpenRouter for chat but want reliable embeddings,
# set both OPENAI_API_KEY (for embeddings) and OPENROUTER_API_KEY (for chat)

