PORT=5000

# API Keys Configuration
# Works with GEMINI_API_KEY, OPENAI_API_KEY, or both!
# 
# For Chat Completions:
#   - Gemini is tried first (if GEMINI_API_KEY is set)
#   - Falls back to OpenAI if Gemini fails
# 
# For Embeddings:
#   - Gemini is tried first (if GEMINI_API_KEY is set and using Gemini embedding models)
#   - Falls back to OpenAI if Gemini fails or if using OpenAI embedding models
# 
# Recommended setup:
#   - GEMINI_API_KEY for chat and embeddings (preferred)
#   - OPENAI_API_KEY as fallback for both chat and embeddings

GEMINI_API_KEY=your_gemini_api_key_here
OPENAI_API_KEY=your_openai_api_key_here

# Model configuration
# For Gemini chat: gemini-2.5-flash, gemini-2.5-pro, gemini-2.0-flash, etc.
# For OpenAI chat: gpt-3.5-turbo, gpt-4, etc.
CHAT_MODEL=gemini-2.5-flash
# Embeddings: Use Gemini embeddings (text-embedding-004, embedding-001) or OpenAI (text-embedding-3-small)
EMBEDDING_MODEL=text-embedding-004

# Token limits
# This is OUTPUT tokens only. Input tokens (your prompt) are separate.
# Set to maximum for longest possible responses - monitor your usage!
# For OpenAI: gpt-3.5-turbo supports up to 4096 tokens
# For Gemini: supports up to 8192 tokens
MAX_TOKENS=4096

